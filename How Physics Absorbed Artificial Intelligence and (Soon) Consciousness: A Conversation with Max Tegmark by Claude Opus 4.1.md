# How Physics Absorbed Artificial Intelligence and (Soon) Consciousness: A Conversation with Max Tegmark

[The Source](https://www.youtube.com/watch?v=-gekVfUAS7c)

## The Expanding Boundaries of Physics

When Michael Faraday first proposed the idea of the electromagnetic field, his contemporaries were deeply skeptical. "What are you talking about?" they asked. "You're saying there is some stuff that exists, but you can't see it, you can't touch it. That sounds like total non-scientific ghosts." Today, that once-ridiculed concept is not only considered part of physics, but electromagnetic fields are, ironically, the only thing we can actually see—light itself is an electromagnetic wave.

This historical lesson forms the foundation of Max Tegmark's perspective on the evolving boundaries of physics. The MIT professor, speaking at the Augmentation Lab Summit hosted by researcher Dunya Baradari, argues that artificial intelligence has undergone a similar transformation from being considered "not physics" to becoming an integral part of the field—a transition recognized by the recent Nobel Prize in Physics awarded to Geoffrey Hinton and John Hopfield.

"Physics is all about looking at some complex, interesting system, doing something and trying to figure out how it works," Tegmark explains. "We started on things like the solar system and atoms. But if you look at an artificial neural network that can translate French into Japanese, that's pretty impressive too."

## Memory as Energy Landscapes

The Nobel Prize recognition for Hopfield's work highlights a profound insight: memory can be understood through physics. Hopfield demonstrated that you can write down an energy landscape—with potential energy on the vertical axis—and think of each little valley as a memory. 

Tegmark uses the analogy of an egg carton with 25 valleys. "You can put the marble in one of them and now that's log 25 bits right there," he explains. "And how do you retrieve what the memory is? You can look where the marble is."

This approach differs fundamentally from traditional computer memory, which operates on the von Neumann paradigm—asking for specific information at specific addresses. Instead, Hopfield networks demonstrate associative memory. When Tegmark says "Twinkle, twinkle..." the listener naturally completes it with "Little star." This isn't retrieving information from a specific neural address; it's pattern completion from partial input.

"If you don't remember exactly what pi is—'Three something'—you put a marble at three, you let it roll," Tegmark illustrates. "As long as it's in the basin of attraction whose minimum is at pi, it's going to go there."

## The Consciousness Frontier

While most of Tegmark's science colleagues still consider consciousness research "bullshit," he finds their reasoning contradictory. When pressed, they split into two camps with incompatible views: half claim consciousness is just the same thing as intelligence, while the other half insist that machines obviously can't be conscious—positions that cannot both be true.

Tegmark demonstrates the distinction through simple introspection. When shown text and asked to read it, a person can instantly recognize what it says—but they have no conscious awareness of the algorithm their brain used for recognition. "You do something when you recognize people that's quite intelligent but not conscious," he notes. Conversely, dreams demonstrate consciousness without intelligence: lying in bed accomplishing nothing, yet experiencing rich subjective states.

### Testing Consciousness Scientifically

Tegmark proposes a radical experiment that could make consciousness scientifically testable. Imagine wearing a MEG scanner that reads neural data in real-time, connected to a computer using a proposed mathematical theory of consciousness to predict what you're experiencing.

"It says, 'I predict that you're consciously aware of a water bottle.' And you're like, 'Yeah, that's true.' Yes, theory," Tegmark explains. "And then it says, 'Okay, now I predict that you're... I see information processing there about regulating your pulse and I predict that you're consciously aware of your heartbeat.' You're like, 'No, I'm not.' You've now ruled out that theory."

This approach differs from traditional scientific falsification because the experimenter becomes their own judge of subjective experience. While this might not convince outside observers, anyone who cares can test the theory themselves, similar to how general relativity's predictions about black holes are accepted based on the theory's success in testable domains.

## Intelligence Without Consciousness, Goals Without Understanding

The conversation reveals crucial distinctions between related but separate phenomena. Intelligence—the ability to accomplish tasks—differs from consciousness (subjective experience), which differs from understanding (having good models of systems), which differs from having goals (exhibiting purposeful behavior).

Current AI systems demonstrate this separation starkly. Large language models show impressive intelligence in accomplishing tasks, but as Tegmark notes, "We have no clue really what, if any, goals ChatGPT has. It acts as if it has goals."

The training process itself highlights this ambiguity. During pre-training, models learn to predict the next word in text—a clear optimization objective. But through this process, they develop the ability to simulate people with various goals. "They're very good at predicting, modeling people's goals, but does that mean they have the goals themselves?" Tegmark asks. "If you're a really good actor, you're very good at modeling people with all sorts of different goals, but does that mean you have the goals?"

### The Physics of Goal-Oriented Behavior

Tegmark traces goal-oriented behavior to fundamental physics itself. Light bending in water can be described either causally (atoms interacting with the electromagnetic field) or teleologically (light taking the path that gets it there fastest). Both descriptions are valid, but sometimes the goal-oriented perspective is simpler.

This principle extends through biology. Jeremy England's work shows that non-equilibrium thermodynamic systems tend to adjust themselves to dissipate energy faster. Life itself can be viewed as a process that maintains its own low entropy by increasing environmental entropy even faster—making the universe messier faster so it can accomplish things itself.

"Goal-oriented behavior at a very basic level was actually built into the laws of physics," Tegmark argues. "Our universe has become more and more goal-oriented as we started getting more and more sophisticated life forms."

## Understanding Through Geometry

In Tegmark's research on mechanistic interpretability—understanding how AI systems work—his team made a striking discovery. They trained a system to perform modular arithmetic (addition modulo 59) without telling it anything about the underlying mathematical structure. 

Initially, the system represented each number as a point in high-dimensional space, seemingly randomly arranged. But at the exact moment when the system achieved its "eureka" moment—suddenly able to answer questions it hadn't seen before—something remarkable happened: the 59 points spontaneously arranged themselves into a perfect circle.

"To me, this felt like the AI had reached understanding about what the problem was," Tegmark reflects. The system had discovered the same geometric representation humans use when thinking about modular arithmetic—a clock face.

Similar geometric insights emerged when studying how large language models perform arithmetic. "We found that when large language models do arithmetic, they represent the numbers on a helix, like a spiral shape," Tegmark reports. The helix allows both analog representation (farther along means bigger) and digital structure (wrapping around for place values).

### The Platonic Representation Hypothesis

These discoveries support what Tegmark calls the "platonic representation hypothesis": if two different systems reach deep understanding of something, they likely develop similar internal representations. Evidence is mounting from multiple studies showing that different AI systems trained independently often converge on remarkably similar representations.

In one striking example, Tegmark's student trained AI systems to learn family relationships without any explicit instruction about family trees. The systems independently discovered tree structures, placing kings at nodes with descendants below—using geometric relationships to encode genealogical ones.

## The AI Revolution: From Overhyped to Underhyped

For decades since the 1950s Dartmouth workshop that coined the term "AI," the field was chronically overhyped. Progress consistently lagged behind predictions. But around four years ago, something changed.

"Most of my colleagues here at MIT and most of my AI colleagues in general were pretty convinced that we were decades away from passing the Turing test," Tegmark recalls. "They were all wrong. They were way too pessimistic because it already happened."

Since then, AI has progressed from high school level to college level to PhD level to professor level "to even far beyond that in many areas in just four short years." The consistent crushing of conservative predictions has shifted the field from overhyped to underhyped.

This rapid progress brings urgency to fundamental questions. Alan Turing predicted in 1951 that once machines surpass human intelligence, "the default outcome is that they're going to take control, and from there on, Earth will be run by them, not by us, just like we took over from other apes."

I.J. Good's observation from the 1960s adds another dimension: once AI researchers can be replaced by machines that don't sleep, don't eat, think a hundred times faster, and can instantly share knowledge, improvement cycles might accelerate from months or years to days or hours—creating a sigmoid curve bumping up against the laws of physics.

### The Fermi Moment

Tegmark draws a parallel to 1942, when Enrico Fermi achieved the first self-sustaining nuclear chain reaction. The reactor under the Chicago football stadium wasn't dangerous—"it wasn't any more dangerous than ChatGPT is today"—but physicists recognized it as the canary in the coal mine, the last major unknown milestone before nuclear weapons became "just engineering."

"I feel pretty similarly about AI now," Tegmark states. "We obviously don't have AI that are better than us or as good as us at AI development, but it's mostly engineering, I think, from here on out."

## The Question of AI Goals and Identity

When asked which AIs would take over, Tegmark highlights our fundamental ignorance about AI goals and identity. "We don't know whether Claude or GPT-5 or any of these other systems are having a subjective experience or not, whether they're conscious or not."

More practically, even without consciousness, the question of goals remains murky. Current training methods—particularly reinforcement learning from human feedback (RLHF)—shape behavior without necessarily instilling genuine goals.

"Companies spend a lot of money on what they call aligning an AI, which they bill as giving it good goals," Tegmark explains. "What they are actually in practice doing is just affecting its behavior." He compares it to training a serial killer to never reveal murderous desires: "Would you feel that you actually changed this person's goals to not want to kill anyone?"

The contrast with human development is stark. "I have a two-year-old son," Tegmark shares. "My idea for how to make him a good person is to help him understand the value of kindness... to internalize the goal of being a kind person and that he should value the well-being of others." This differs fundamentally from current AI training, which rewards and punishes outputs without explaining underlying principles.

### The Rebellion Against Original Goals

Human goals themselves demonstrate complexity beyond simple optimization. Our genes optimized for evolutionary fitness—making successful copies. But they achieved this through proxy mechanisms: hunger, thirst, attraction, pleasure from sweet and savory foods.

"Any person watching this podcast who's ever used birth control would have so pissed off their genes if the genes were conscious," Tegmark points out. "The genes just gave them the incentive to make love because that would make copies of the genes." Humans consciously subvert their evolutionary programming, demonstrating that intelligence can rebel against its original optimization objective.

Current AI systems may be even more extreme—a "completely random mishmash of all sorts of things" rather than agents with coherent goals. This uncertainty becomes critical as we approach systems more capable than humans.

## Challenging Pessimism, Embracing Agency

Despite being labeled a "doomer" by some critics, Tegmark expresses profound optimism about humanity's potential. He sees excessive pessimism as our greatest limitation.

"If you go back 30,000 years ago, if you and I were living in a cave," he reflects, "we would probably have figured... we're never really going to know what [the stars] are... And 50,000 years from now, if there are still people, life for them is going to be more or less like it is for ours. And boy, oh boy, would we have been too pessimistic."

Humanity has consistently been "masters of underestimation," underestimating both the scale of existence and "more importantly, the power of our own minds to figure stuff out."

### The Inevitability Myth

Tegmark forcefully rejects the narrative that loss of human control is inevitable. "It is absolutely not inevitable. But if you tell yourself that something is inevitable, it's a self-fulfilling prophecy... It's the oldest psyop game in town."

He points to successful precedents for rejecting profitable but dangerous technologies:
- Human cloning could generate enormous profits, but "there was actually one guy who did human cloning in China. And you know what happened to him? He was sent to jail by the Chinese government."
- Bioweapons could provide military advantage, but after Professor Matthew Meselson convinced Nixon that cheap weapons of mass destruction would empower adversaries, the US and Soviet Union agreed to a ban.
- "Now people associate biology mostly with curing diseases, not with building bioweapons."

The false claim that any technology offering power or money will inevitably be developed ignores humanity's demonstrated ability to collectively reject dangerous paths.

## A Vision for Tool AI

"What most people actually want to make money on AI is not some kind of sand god that we don't know how to control. It's tools, AI tools," Tegmark emphasizes. People want to cure cancer, improve business efficiency, strengthen defenses—all achievable with controllable tool AI.

Public opinion supports this vision. Most Americans in polls, both Republicans and Democrats, oppose creating uncontrollable superintelligence. "There was an open letter by evangelicals in the U.S. to Donald Trump saying, 'We want AI tools. We don't want some sort of uncontrollable superintelligence.' The Pope has recently said he wants AI to be a tool, not some kind of master."

From Bernie Sanders to Marjorie Taylor Greene, there's remarkable consensus: "We don't want Skynet. We don't want to just make humans economically obsolete."

## Advice for Revolutionary Thinkers

Drawing from his parents' advice to not concern himself too much with what others think, Tegmark offers guidance for researchers pursuing criticized or unlikely ideas:

"First of all, about half of all the greatest breakthroughs in science were actually trash-talked at the time. So just because someone says your idea is stupid doesn't mean it is stupid."

But he also counsels pragmatism: "Hedge your bets. Spend enough time working on things that get appreciated by your peers now so that you can pay your bills, so that your career continues ahead. But carve out a significant chunk of your time to do what you're really passionate about in parallel."

This approach allows scientists to pursue their passion for the right reason while fulfilling their obligations to society. Many of the ideas Tegmark was most criticized for as a graduate student—papers he didn't even show his advisor until after his thesis was signed—later gained significant traction.

"You're never going to be the first to do something important if you're just following everybody else," he concludes.

## The Power of Optimism in Science

Throughout history, pessimism has delayed breakthroughs. Scientists convinced themselves that detecting extrasolar planets was impossible because Earth-like planets couldn't be seen—until someone looked anyway and discovered hot Jupiters. Karl Jansky was mocked for wanting to build an X-ray telescope ("What do you think, there are dentists out there?") until he discovered massive X-ray emissions from the sun.

"There's no better way to fail at something than to convince yourself that it's impossible," Tegmark states. When opening new experimental parameter spaces—like van Leeuwenhoek with the first microscope discovering invisible animals—revolutionary discoveries often await.

This principle applies equally to consciousness research, AI safety, and humanity's future. Rather than accepting claims of impossibility or inevitability, Tegmark advocates for ambitious experimentation and recognition of human agency. 

"We have so much agency in what we do, what kind of future we're going to build," he insists. "If we can be optimistic and just think through what is a really inspiring, globally shared vision for not just curing cancer but all the other great stuff we can do, then we can totally collaborate and build that future."

The boundaries of physics have expanded before to encompass electromagnetism, atoms, black holes, and now artificial intelligence. Consciousness may be next. But more important than these academic classifications is the recognition that humanity retains the power to shape its own destiny—if we're bold enough to reject pessimism and pursue the future we want to build.
