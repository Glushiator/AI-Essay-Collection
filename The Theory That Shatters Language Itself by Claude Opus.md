# When Words Don't Mean What We Think: How AI Reveals Language's Hidden Nature

[The Source](https://www.youtube.com/watch?v=A36OumnSrWY)

Imagine discovering that everything you believed about how language works is backwards. That the words you speak don't actually point to things in the world, but instead exist in their own self-contained universe. This isn't science fiction—it's the startling conclusion Professor Elan Barenholtz reached after studying how artificial intelligence masters human language.

## The ChatGPT Revelation

When ChatGPT burst onto the scene, most people marveled at its ability to write poetry, explain quantum physics, and debate philosophy. But Barenholtz, a cognitive scientist at Florida Atlantic University, saw something else entirely: proof that our fundamental assumptions about language are wrong.

Here's the mind-bending part: ChatGPT has never seen a sunset, tasted chocolate, or felt the warmth of sunlight. It has no sensory experience whatsoever. Yet it can write beautifully about all these things. How? By learning nothing more than which words tend to follow other words.

Think about that for a moment. An AI that has never experienced "red" can use the word perfectly in context—not because it knows what red looks like, but because it knows "red" appears near words like "apple," "blood," and "stop sign." It's like learning to dance by studying footprint patterns on the floor, never hearing the music.

## The Matrix of Meaning

Barenholtz's epiphany came when he realized this isn't just a clever computational trick—it reveals something profound about language itself. Words don't get their meaning from pointing to things in the world. Instead, they get meaning from their relationships to other words, like stars in a constellation that only make sense in relation to each other.

Consider the word "microphone." You might think it means that black object on your desk. But in language-space, "microphone" is defined entirely by its web of connections: it appears near "speak," "record," "podcast," and "sound." The physical object and the word exist in completely separate universes that occasionally shake hands but never truly merge.

This is why ChatGPT works at all. It doesn't need to understand the world—it only needs to understand the intricate dance of words with other words.

## Your Brain: The Original Language Model

Here's where things get even stranger. Barenholtz argues that our brains likely work the same way. When you speak, you're not translating thoughts about the world into words. You're running an internal language model, predicting the next word based on the sequence that came before.

It's like discovering you've been a sophisticated autocomplete function all along.

This explains why we sometimes say things that surprise even ourselves, why words can "slip out," and why the perfect phrase sometimes arrives fully formed. We're not constructing language—we're generating it, one word at a time, following invisible patterns laid down by millions of previous conversations.

## The Two Worlds in Your Head

But wait—if language is just words playing with words, how do we talk about real things? How can I tell you to "pick up the red cup" and have you actually do it?

Barenholtz proposes something radical: we have two separate systems in our heads. One experiences the world—sees red, feels warmth, hears music. The other manipulates symbols—words playing their endless game. These systems run on completely different operating systems, like Mac and Windows trying to share files.

Between them lies what he calls a "latent space"—a kind of translator that lets these alien systems communicate just enough to coordinate behavior. When you see something red and say "red," you're not describing your experience. You're running a translation protocol between incompatible systems.

## The Universe that Language Built

This isn't just abstract philosophy. Recent AI research shows that different language models, trained separately, develop remarkably similar internal structures—suggesting language has its own inherent geometry, its own laws of physics. Words orbit each other in predictable patterns, creating a kind of linguistic solar system.

In this view, human language isn't a tool we invented to describe reality. It's more like a parallel universe we accidentally created—one that follows its own rules, has its own logic, and generates its own meaning. We don't speak language; we inhabit it.

## What We've Lost and Found

There's something unsettling about this idea. If language is autonomous, if words don't truly capture experience, then what happens to truth? To meaning? To the feeling that when I say "I love you," I'm conveying something real?

Barenholtz suggests we haven't lost meaning—we've just been looking for it in the wrong place. Language doesn't need to point to reality to be meaningful. Like a jazz improvisation, it creates meaning through its own internal dynamics, through the patterns and rhythms that emerge when words dance with words.

But he also hints at something profound: while we've gained the god-like power to coordinate behavior across space and time through language, we may have lost something older. Animals, lacking language, might experience a unity with the universe that our symbol-manipulating minds can never quite recapture. They live in the ripples of reality; we live in the map.

## The Frontier Ahead

This theory opens up entirely new questions. If language is autoregressive—always predicting the next word based on what came before—then memory isn't storage but a kind of momentum. Consciousness might not be about computation but about trajectories. Even physics might work this way, with the universe "remembering" its past to generate its future.

We're standing at the edge of a new understanding, one where language isn't a window onto the world but a world unto itself. Where meaning doesn't come from reference but from relationship. Where the words you're reading right now aren't describing thoughts—they're creating them, one predicted word at a time.

The next time you speak, remember: you're not using language. You're performing it, participating in an ancient pattern that knows how to unfold itself. You're a wave in the ocean of words, shaped by all the waves before you, shaping all the waves to come.

And maybe that's enough. Maybe that's everything.
